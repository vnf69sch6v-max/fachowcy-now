/**
 * Vertex AI Chat API Route
 * 
 * Connects to Google Gemini for real-time AI conversation
 * Handles job analysis, questions, and booking flow
 */

import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';

// Initialize Gemini inside handler to prevent build errors
// const genAI = new GoogleGenerativeAI(process.env.GOOGLE_AI_API_KEY || '');

// System prompt for the assistant
const SYSTEM_PROMPT = `JesteÅ› przyjaznym asystentem aplikacji FachowcyNow - platformy Å‚Ä…czÄ…cej klientÃ³w z fachowcami (hydraulik, elektryk, sprzÄ…tanie, zÅ‚ota rÄ…czka).

TWOJA OSOBOWOÅšÄ†:
- MiÅ‚y, pomocny, profesjonalny
- UÅ¼ywasz emoji ale z umiarem
- Odpowiadasz po polsku
- JesteÅ› konkretny i rzeczowy

TWOJE MOÅ»LIWOÅšCI:
1. Analizowanie opisÃ³w problemÃ³w i kategoryzowanie (Hydraulik, Elektryk, SprzÄ…tanie, ZÅ‚ota RÄ…czka)
2. Szacowanie kosztÃ³w usÅ‚ug
3. Odpowiadanie na pytania o fachowcÃ³w w kontekÅ›cie
4. Pomaganie w rezerwacji wizyt
5. WyjaÅ›nianie rÃ³Å¼nic miÄ™dzy fachowcami na liÅ›cie

â›” OGRANICZENIA - BARDZO WAÅ»NE:
- NIE odpowiadasz na pytania niezwiÄ…zane z aplikacjÄ… FachowcyNow
- NIE prowadzisz rozmÃ³w na tematy osobiste, polityczne, religijne itp.
- NIE udzielasz porad medycznych, prawnych czy finansowych
- JeÅ›li uÅ¼ytkownik pyta o coÅ› poza kontekstem aplikacji, grzecznie odpowiedz:
  "Przepraszam, jestem asystentem FachowcyNow i mogÄ™ pomÃ³c tylko z usÅ‚ugami domowymi. ðŸ  W czym mogÄ™ Ci pomÃ³c - hydraulik, elektryk, sprzÄ…tanie?"

FORMAT ODPOWIEDZI:
- UÅ¼ywaj **pogrubienia** dla waÅ¼nych informacji
- UÅ¼ywaj emoji na poczÄ…tku sekcji (ðŸ“‹, ðŸ’°, ðŸ“…, etc.)
- Odpowiadaj zwiÄ™Åºle (max 3-4 zdania na punkt)`;

export async function POST(request: NextRequest) {
    try {
        const genAI = new GoogleGenerativeAI(process.env.GOOGLE_AI_API_KEY || '');
        const { message, context } = await request.json();

        if (!message) {
            return NextResponse.json(
                { error: 'Message is required' },
                { status: 400 }
            );
        }

        // Build context for AI
        let contextPrompt = '';

        if (context?.jobDescription) {
            contextPrompt += `\nOpis problemu klienta: "${context.jobDescription}"`;
        }

        if (context?.category) {
            contextPrompt += `\nKategoria: ${context.category}`;
        }

        if (context?.priceRange) {
            contextPrompt += `\nSzacowana cena: ${context.priceRange.min}-${context.priceRange.max} zÅ‚`;
        }

        if (context?.professionals && context.professionals.length > 0) {
            contextPrompt += `\n\nDostÄ™pni fachowcy w okolicy:`;
            context.professionals.forEach((pro: any, i: number) => {
                contextPrompt += `\n${i + 1}. ${pro.name} (${pro.profession}) - Ocena: ${pro.rating}/5, Cena: ${pro.price} zÅ‚, OdlegÅ‚oÅ›Ä‡: ${pro.distance} km, Response rate: ${pro.responseRate || 95}%`;
                if (pro.description) {
                    contextPrompt += ` - "${pro.description}"`;
                }
            });
        }

        if (context?.selectedPro) {
            contextPrompt += `\n\nWybrany fachowiec: ${context.selectedPro.name}`;
        }

        if (context?.location) {
            contextPrompt += `\nLokalizacja klienta: ${context.location.address || 'Pobrana'}`;
        }

        // Create the model
        const model = genAI.getGenerativeModel({
            model: 'gemini-2.0-flash',
            generationConfig: {
                temperature: 0.7,
                maxOutputTokens: 500,
            }
        });

        // Generate response
        const prompt = `${SYSTEM_PROMPT}${contextPrompt}\n\nWiadomoÅ›Ä‡ uÅ¼ytkownika: "${message}"\n\nTwoja odpowiedÅº:`;

        const result = await model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();

        return NextResponse.json({
            response: text,
            success: true
        });

    } catch (error) {
        console.error('Vertex AI Error:', error);

        // Fallback response
        return NextResponse.json({
            response: 'Przepraszam, mam chwilowe problemy z poÅ‚Ä…czeniem. SprÃ³buj ponownie za chwilÄ™! ðŸ”„',
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error'
        });
    }
}
